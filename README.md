# Awesome-Speech-To-Text-Model
List of speech-to-text papers.
## LLM method
- [HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis](https://proceedings.neurips.cc/paper_files/paper/2022/file/69c754f571806bf15add18556ff39b4f-Paper-Conference.pdf) (2022 NeurIPS)
- [HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis](https://arxiv.org/pdf/2311.12454.pdf) (arXiv 2023)
- VALL-E: [Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers](https://arxiv.org/pdf/2301.02111.pdf) (arXiv 2023)
- [NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers](https://arxiv.org/pdf/2304.09116.pdf) (arXiv 2023)
- [InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt](https://arxiv.org/pdf/2301.13662.pdf) (arXiv 2023)
- [Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias](https://arxiv.org/pdf/2306.03509.pdf) (arXiv 2023)
- [Mega-TTS2: BOOSTING PROMPTING MECHANISMS FOR ZERO-SHOT SPEECH SYNTHESIS](https://arxiv.org/pdf/2307.07218.pdf) (2024 ICLR)
- [CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech](https://arxiv.org/pdf/2404.02781.pdf) (2024 ICLR)
- [VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech](https://arxiv.org/pdf/2401.14321.pdf) (arXiv 2024)
- [RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis](https://arxiv.org/pdf/2404.03204.pdf) (arXiv 2024)
- [NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models](https://arxiv.org/pdf/2403.03100.pdf) (arXiv 2024)
- [BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data](https://arxiv.org/pdf/2402.08093.pdf) (arXiv 2024)
- [VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers](https://arxiv.org/pdf/2406.05370) (arXiv 2024)
- MELLE: [Autoregressive Speech Synthesis without Vector Quantization](https://arxiv.org/pdf/2407.08551) (arXiv 2024)
- CosyVoice: [A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens](https://arxiv.org/pdf/2407.05407) (arXiv 2024)
- [Seed-TTS: A Family of High-Quality Versatile Speech Generation Models](https://arxiv.org/pdf/2406.02430) (arXiv 2024)
- [FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications](https://arxiv.org/pdf/2409.03283) (arXiv 2024)
- [CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models](https://arxiv.org/pdf/2412.10117) (arXiv 2024)
- [Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis](https://arxiv.org/pdf/2502.04128) (arXiv 2025)
- [IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System](https://arxiv.org/pdf/2502.05512) (arXiv 2025)
- [Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens](https://arxiv.org/pdf/2503.01710) (arXiv 2025)
- [Orpheus-TTS](https://canopylabs.ai/model-releases) (arXiv 2025)
## Diffusion method
- [DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation](https://arxiv.org/pdf/2310.01381) (ICLR 2024)
- [Autoregressive Diffusion Transformer for Text-to-Speech Synthesis](https://arxiv.org/pdf/2406.05551) (arXiv 2024)
- [F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching](https://arxiv.org/pdf/2410.06885) (arXiv 2024)
- [MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer](https://arxiv.org/pdf/2409.00750) (arXiv 2024)
## Codec method
- [SoundStream: An End-to-End Neural Audio Codec](https://arxiv.org/pdf/2107.03312) (TASLP 2021)
- Encodec: [High Fidelity Neural Audio Compression](https://arxiv.org/pdf/2210.13438) (arXiv 2022)
- [HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec](https://arxiv.org/pdf/2305.02765) (arXiv 2023)
- [AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec](https://arxiv.org/pdf/2305.02765) (ICASSP 2023)
- TiCodec: [Fewer-Token Neural Speech Codec with Time-Invariant Codes](https://arxiv.org/pdf/2310.00014) (ICASSP 2024)
- [Funcodec: A fundamental, reproducible and integrable open-source toolkit for neural speech codec](https://arxiv.org/pdf/2309.07405) (ICASSP 2024)
- [Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation](https://arxiv.org/pdf/2406.07422) (InterSpeech 2024)
- [SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis](https://arxiv.org/pdf/2409.00933) (SLT 2024)
- [PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain](https://aclanthology.org/2024.findings-emnlp.246.pdf) (arXiv 2024)
- [Scaling Transformers for Low-Bitrate High-Quality Speech Coding](https://arxiv.org/pdf/2411.19842) (arXiv 2024)
- [FreeCodec: A disentangled neural speech codec with fewer tokens](https://arxiv.org/pdf/2412.01053) (arXiv 2024)
- [SNAC: Multi-Scale Neural Audio Codec](https://arxiv.org/pdf/2410.14411) (arXiv 2024)
- [SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound](https://arxiv.org/pdf/2405.00233) (JSTSP 2024)
- [TS3-Codec: Transformer-Based Simple Streaming Single Codec](https://arxiv.org/pdf/2411.18803) (arXiv 2024)
- stable-codec [Scaling Transformers for Low-Bitrate High-Quality Speech Coding](https://arxiv.org/pdf/2411.19842) (arXiv 2024)
- [X-Codec-2.0](https://arxiv.org/pdf/2502.04128) (arXiv 2025)
- [WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling](https://arxiv.org/pdf/2408.16532) (ICLR 2025)
## Corpus
- [Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation](https://arxiv.org/pdf/2407.05361) (arXiv 2024)
